{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a5fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "import clip\n",
    "import whisper\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5d03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# CLIP\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "\n",
    "# Whisper (multilingual, handles Marathi, Hindi, English, etc)\n",
    "whisper_model = whisper.load_model(\"base\")  # or \"small\" if you want better quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1551c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "QDRANT_KEY = os.getenv(\"QDRANT_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_KEY\n",
    ")\n",
    "\n",
    "COLLECTION_NAME = \"GNOSIS_V2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1710b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# client.create_collection(\n",
    "#     collection_name=\"GNOSIS_V2\",\n",
    "#     vectors_config={\n",
    "#         \"text\": VectorParams(size=512, distance=Distance.COSINE),\n",
    "#         \"vision\": VectorParams(size=512, distance=Distance.COSINE),\n",
    "#         \"video\": VectorParams(size=512, distance=Distance.COSINE),\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb964d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_VIDEO_ROOT = r\"D:/STUDY/PROJECTS/GNOSIS/Resources/Videos\"\n",
    "\n",
    "DOMAINS = {\n",
    "    \"medical\": {\n",
    "        \"folder\": \"Medical\",\n",
    "        \"excel\": \"medicalURL.xlsx\"\n",
    "    },\n",
    "    \"politics\": {\n",
    "        \"folder\": \"Politics\",\n",
    "        \"excel\": \"politicsURL.xlsx\"\n",
    "    }\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "UPLOAD_BATCH = 16\n",
    "FRAMES_PER_VIDEO = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23c02cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=8):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames <= 0:\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    idxs = np.linspace(0, total_frames - 1, num_frames).astype(int)\n",
    "\n",
    "    frames = []\n",
    "    for i in idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(i))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61700ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_video(video_path):\n",
    "    try:\n",
    "        result = whisper_model.transcribe(video_path)\n",
    "        return result.get(\"text\", \"\").strip()\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Transcription failed:\", video_path, e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65a26975",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_vec_batch = []\n",
    "text_vec_batch = []\n",
    "meta_batch = []\n",
    "transcript_batch = []\n",
    "points_buffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45138660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Processing MEDICAL\n",
      "Rows: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:42<00:00,  8.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Processing POLITICS\n",
      "Rows: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "for domain_name, cfg in DOMAINS.items():\n",
    "\n",
    "    folder = os.path.join(BASE_VIDEO_ROOT, cfg[\"folder\"])\n",
    "    excel_path = os.path.join(folder, cfg[\"excel\"])\n",
    "\n",
    "    print(f\"\\nðŸ“ Processing {domain_name.upper()}\")\n",
    "\n",
    "    if not os.path.exists(excel_path):\n",
    "        print(\"âŒ Missing Excel:\", excel_path)\n",
    "        continue\n",
    "\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    print(\"Rows:\", len(df))\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "        fname = str(row[\"file_name\"]).strip()\n",
    "        video_url = str(row[\"video_url\"]).strip()\n",
    "        label = str(row[\"label\"]).strip()\n",
    "\n",
    "        # Try common extensions\n",
    "        possible_paths = [\n",
    "            os.path.join(folder, fname),\n",
    "            os.path.join(folder, fname + \".mp4\"),\n",
    "            os.path.join(folder, fname + \".mkv\"),\n",
    "            os.path.join(folder, fname + \".webm\"),\n",
    "        ]\n",
    "\n",
    "        video_path = None\n",
    "        for p in possible_paths:\n",
    "            if os.path.exists(p):\n",
    "                video_path = p\n",
    "                break\n",
    "\n",
    "        if video_path is None:\n",
    "            print(\"âš ï¸ Missing video file for:\", fname)\n",
    "            continue\n",
    "\n",
    "        # =========================\n",
    "        # 1. Extract frames\n",
    "        # =========================\n",
    "        frames = extract_frames(video_path, FRAMES_PER_VIDEO)\n",
    "        if not frames:\n",
    "            continue\n",
    "\n",
    "        frame_tensors = torch.stack([\n",
    "            preprocess(Image.fromarray(f)) for f in frames\n",
    "        ]).to(device)\n",
    "\n",
    "        # =========================\n",
    "        # 2. Encode video frames\n",
    "        # =========================\n",
    "        with torch.no_grad():\n",
    "            frame_vecs = clip_model.encode_image(frame_tensors)\n",
    "            frame_vecs = frame_vecs / frame_vecs.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        video_vec = frame_vecs.mean(dim=0).cpu().numpy()\n",
    "\n",
    "        # =========================\n",
    "        # 3. Transcribe\n",
    "        # =========================\n",
    "        transcript = transcribe_video(video_path)\n",
    "\n",
    "        if transcript.strip():\n",
    "            tokens = clip.tokenize([transcript], truncate=True).to(device)\n",
    "            with torch.no_grad():\n",
    "                text_vec = clip_model.encode_text(tokens).cpu().numpy()[0]\n",
    "        else:\n",
    "            text_vec = None\n",
    "\n",
    "        # =========================\n",
    "        # 4. Meta\n",
    "        # =========================\n",
    "        meta = {\n",
    "            \"modality\": \"video\",\n",
    "            \"domain\": domain_name,\n",
    "            \"dataset\": \"Video_Demo\",\n",
    "            \"filename\": os.path.basename(video_path),\n",
    "            \"video_path\": video_path,\n",
    "            \"video_url\": video_url,\n",
    "            \"label\": label,\n",
    "            \"has_transcript\": bool(transcript.strip()),\n",
    "        }\n",
    "\n",
    "        # =========================\n",
    "        # 5. Batch\n",
    "        # =========================\n",
    "        video_vec_batch.append(video_vec)\n",
    "        text_vec_batch.append(text_vec)\n",
    "        meta_batch.append(meta)\n",
    "        transcript_batch.append(transcript)\n",
    "\n",
    "        # =========================\n",
    "        # 6. Upload batch\n",
    "        # =========================\n",
    "        if len(video_vec_batch) >= BATCH_SIZE:\n",
    "\n",
    "            for vvec, tvec, meta, trans in zip(video_vec_batch, text_vec_batch, meta_batch, transcript_batch):\n",
    "\n",
    "                vectors_payload = {\n",
    "                    \"video\": vvec.tolist()\n",
    "                }\n",
    "\n",
    "                if tvec is not None:\n",
    "                    vectors_payload[\"text\"] = tvec.tolist()\n",
    "\n",
    "                point = PointStruct(\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    vector=vectors_payload,\n",
    "                    payload={\n",
    "                        **meta,\n",
    "                        \"transcript\": trans\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                points_buffer.append(point)\n",
    "\n",
    "            video_vec_batch = []\n",
    "            text_vec_batch = []\n",
    "            meta_batch = []\n",
    "            transcript_batch = []\n",
    "\n",
    "            if len(points_buffer) >= UPLOAD_BATCH:\n",
    "                client.upsert(collection_name=COLLECTION_NAME, points=points_buffer)\n",
    "                print(\"â¬†ï¸ Uploaded\", len(points_buffer), \"video points\")\n",
    "                points_buffer = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2332fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬†ï¸ Final upload: 7\n",
      "âœ… Video ingestion complete\n"
     ]
    }
   ],
   "source": [
    "if video_vec_batch:\n",
    "    for vvec, tvec, meta, trans in zip(video_vec_batch, text_vec_batch, meta_batch, transcript_batch):\n",
    "\n",
    "        vectors_payload = {\n",
    "            \"video\": vvec.tolist()\n",
    "        }\n",
    "\n",
    "        if tvec is not None:\n",
    "            vectors_payload[\"text\"] = tvec.tolist()\n",
    "\n",
    "        point = PointStruct(\n",
    "            id=str(uuid.uuid4()),\n",
    "            vector=vectors_payload,\n",
    "            payload={\n",
    "                **meta,\n",
    "                \"transcript\": trans\n",
    "            }\n",
    "        )\n",
    "\n",
    "        points_buffer.append(point)\n",
    "\n",
    "if points_buffer:\n",
    "    client.upsert(collection_name=COLLECTION_NAME, points=points_buffer)\n",
    "    print(\"â¬†ï¸ Final upload:\", len(points_buffer))\n",
    "\n",
    "print(\"âœ… Video ingestion complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a95a1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64612526 https://youtu.be/zXw0qDlj1GY?si=pb0FU0VA7j61XAgG\n",
      "0.6240506 https://youtube.com/shorts/X34XT2owHYM?si=0RIF7ucy_vTcVVK9\n",
      "0.58934754 https://youtube.com/shorts/48FyhomD1zI?si=kceYOaQ14aviLTIo\n",
      "0.57342994 https://youtu.be/5c3wWNsmLA0?si=FH80c67SvlYNyH39\n",
      "0.541459 https://youtu.be/g3Y3J_Z_CdM?si=ukuSRIWth7PS3ieg\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"sonu sood campaigning news was it fake?\"\n",
    "\n",
    "tokens = clip.tokenize([QUERY]).to(device)\n",
    "with torch.no_grad():\n",
    "    qvec = clip_model.encode_text(tokens).cpu().numpy()[0]\n",
    "\n",
    "result = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=qvec.tolist(),\n",
    "    using=\"text\",\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "for hit in result.points:\n",
    "    print(hit.score, hit.payload.get(\"video_url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684c072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ TEXT RESULTS (score > 0.85) ================\n",
      "\n",
      "#1 SCORE=0.8963\n",
      "TITLE / FILE: Sonu Sood exposed for fake charity spending during pandemic\n",
      "URL: https://reddit.com/sood-fake-charity\n",
      "\n",
      "#2 SCORE=0.8480\n",
      "TITLE / FILE: Did Sonu Sood misuse charity funds of â‚¹19 crore?\n",
      "URL: https://healthrumors.net/sood-misuse\n",
      "\n",
      "#3 SCORE=0.8277\n",
      "TITLE / FILE: Sonu Sood â€œfake helperâ€ rumors during COVID\n",
      "URL: https://insta.com/reel/sood-fake\n",
      "\n",
      "#4 SCORE=0.8259\n",
      "TITLE / FILE: Celebrity fraud: Sonu Sood kept COVID relief funds\n",
      "URL: whatsapp://share/sood-covid-fraud\n",
      "\n",
      "#5 SCORE=0.8104\n",
      "TITLE / FILE: Sonu Sood took â‚¹19 cr donations but gave only â‚¹2-3 cr\n",
      "URL: https://example.com/sood-donations-19cr\n",
      "\n",
      "\n",
      "================ IMAGE RESULTS (score > 0.85) ================\n",
      "\n",
      "\n",
      "================ VIDEO RESULTS (score > 0.85) ================\n",
      "\n",
      "#1 SCORE=0.2719\n",
      "FILE: Fake_Covid-19_Donation_Campaign_Sonu_Sood_1080P.mp4\n",
      "URL: https://youtu.be/zXw0qDlj1GY?si=pb0FU0VA7j61XAgG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===================== CONFIG =====================\n",
    "QUERY = \"Sonu Sood for fake charity and improper funds use?\"\n",
    "\n",
    "TEXT_COLLECTION = \"GNOSIS\"\n",
    "VIDEO_COLLECTION = \"GNOSIS_V2\"\n",
    "\n",
    "SCORE_THRESHOLD = 0.6   # âš ï¸ Qdrant scores are 0â€“1, not 0â€“10\n",
    "\n",
    "# ===================== EMBED QUERY =====================\n",
    "tokens = clip.tokenize([QUERY], truncate=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    qvec = clip_model.encode_text(tokens).cpu().numpy()[0]\n",
    "\n",
    "qvec = qvec.tolist()\n",
    "\n",
    "# ===================== SEARCH =====================\n",
    "\n",
    "# ---- 5 TEXT from GNOSIS ----\n",
    "text_results = client.query_points(\n",
    "    collection_name=TEXT_COLLECTION,\n",
    "    query=qvec,\n",
    "    using=\"text\",\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# ---- 2 IMAGES from GNOSIS ----\n",
    "image_results = client.query_points(\n",
    "    collection_name=TEXT_COLLECTION,\n",
    "    query=qvec,\n",
    "    using=\"vision\",\n",
    "    limit=2,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# ---- 1 VIDEO from GNOSIS_V2 ----\n",
    "video_results = client.query_points(\n",
    "    collection_name=VIDEO_COLLECTION,\n",
    "    query=qvec,\n",
    "    using=\"video\",\n",
    "    limit=1,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# ===================== PRINT RESULTS (FILTERED) =====================\n",
    "\n",
    "print(\"\\n================ TEXT RESULTS (score > 0.85) ================\\n\")\n",
    "for i, hit in enumerate(text_results.points, 1):\n",
    "    if hit.score < SCORE_THRESHOLD:\n",
    "        continue\n",
    "\n",
    "    print(f\"#{i} SCORE={hit.score:.4f}\")\n",
    "    print(\"TITLE / FILE:\", hit.payload.get(\"title\") or hit.payload.get(\"filename\"))\n",
    "    print(\"URL:\", hit.payload.get(\"source_url\") or hit.payload.get(\"url\"))\n",
    "    print()\n",
    "\n",
    "print(\"\\n================ IMAGE RESULTS (score > 0.85) ================\\n\")\n",
    "for i, hit in enumerate(image_results.points, 1):\n",
    "    if hit.score < SCORE_THRESHOLD:\n",
    "        continue\n",
    "\n",
    "    print(f\"#{i} SCORE={hit.score:.4f}\")\n",
    "    print(\"FILE:\", hit.payload.get(\"filename\"))\n",
    "    print(\"PATH:\", hit.payload.get(\"source_path\"))\n",
    "    print()\n",
    "\n",
    "print(\"\\n================ VIDEO RESULTS (score > 0.85) ================\\n\")\n",
    "for i, hit in enumerate(video_results.points, 1):\n",
    "    if hit.score < SCORE_THRESHOLD-0.5:\n",
    "        continue\n",
    "\n",
    "    print(f\"#{i} SCORE={hit.score:.4f}\")\n",
    "    print(\"FILE:\", hit.payload.get(\"filename\"))\n",
    "    print(\"URL:\", hit.payload.get(\"video_url\"))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25200546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitGnosisDataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
